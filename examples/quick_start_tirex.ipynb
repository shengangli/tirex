{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8TNBP-AFejT"
      },
      "source": [
        "### [Only In Google Colab] Setup TiRex in Colab\n",
        "\n",
        "Make sure that you selected a **GPU runtime in Google Colab**\n",
        "Runtime ->  Change Runtime Type -> Select A100 / L4 / T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvLGXeSLFejU"
      },
      "outputs": [],
      "source": [
        "# Only for Google Colab Notebook!\n",
        "\n",
        "import os\n",
        "\n",
        "# Clone TiRep Repo\n",
        "!git clone https://github.com/NX-AI/tirex\n",
        "\n",
        "# Install TiRex\n",
        "os.chdir('/content/tirex')\n",
        "!pip install .[gluonts]\n",
        "\n",
        "# Set Workin Dir to notebooks folder\n",
        "os.chdir('/content/tirex/examples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovev2Qd0FejW"
      },
      "source": [
        "### Imports and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AByTmYiFejX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from util_plot import plot_fc\n",
        "\n",
        "# import os\n",
        "# os.environ[\"TIREX_NO_CUDA\"] = \"1\"   # Experimental!!: Turns off sLSTM CUDA kernels if you have problems but be aware of the downsides! (see repository FAQ)\n",
        "from tirex import ForecastModel, load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se98NnD5FejX"
      },
      "source": [
        "### TiRex Forecast in 2 Lines\n",
        "\n",
        "1) Load Model\n",
        "2) Generate Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8J4bhVnFejY"
      },
      "outputs": [],
      "source": [
        "# 1) Load Model\n",
        "model: ForecastModel = load_model(\"NX-AI/TiRex\")\n",
        "\n",
        "# 2) Short Horizon - Example\n",
        "quantiles, mean = model.forecast(ctx_s, prediction_length=24)\n",
        "plot_fc(ctx_s, quantiles[0], future_s)\n",
        "\n",
        "# 2) Long Horizon - Example\n",
        "quantiles, mean = model.forecast(ctx_l, prediction_length=768)\n",
        "plot_fc(ctx_l, quantiles[0], future_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLEvjGu8FejY"
      },
      "source": [
        "### Input Options\n",
        "\n",
        "TiRex supports forecasting with different input types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emhaMOPaFejZ"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor(np.genfromtxt(Path.cwd() / \"air_passengers.csv\"))  # Load Example\n",
        "\n",
        "# Torch tensor (2D or 1D)\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24)\n",
        "print(\"Predictions (Torch tensor):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "# List of Torch tensors (List of 1D) - will be padded\n",
        "list_torch_data = [data, data, data]\n",
        "quantiles, means = model.forecast(context=list_torch_data, prediction_length=24, batch_size=2)\n",
        "print(\"Predictions (List of Torch tensors):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "# NumPy array (2D or 1D)\n",
        "quantiles, means = model.forecast(context=data.numpy(), prediction_length=24, output_type=\"torch\")\n",
        "print(\"Predictions (NumPy):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# List of NumPy arrays (List of 1D) - will be padded\n",
        "list_numpy_data = [data.numpy()]  # Split into 3 sequences\n",
        "quantiles, means = model.forecast(context=list_numpy_data, prediction_length=24)\n",
        "print(\"Predictions (List of NumPy arrays):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# GluonTS Dataset\n",
        "try:\n",
        "    from typing import cast\n",
        "\n",
        "    from gluonts.dataset import Dataset\n",
        "\n",
        "    gluon_dataset = cast(Dataset, [{\"target\": data, \"item_id\": 1}, {\"target\": data, \"item_id\": 22}])\n",
        "    quantiles, means = model.forecast_gluon(gluon_dataset, prediction_length=24)\n",
        "    print(\"Predictions GluonDataset:\\n\", type(quantiles), quantiles.shape)\n",
        "    # If you use also `glutonts` as your output type the start_time and item_id get preserved accordingly\n",
        "    predictions_gluon = model.forecast_gluon(gluon_dataset, prediction_length=24, output_type=\"gluonts\")\n",
        "    print(\"Predictions GluonDataset:\\n\", type(predictions_gluon), type(predictions_gluon[0]))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # To use the gluonts function you need to install the optional dependency\n",
        "    # pip install tirex[gluonts]\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC1syXraFejZ"
      },
      "source": [
        "### Output Options\n",
        "\n",
        "\n",
        "TiRex supports different output types for the forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjzqAO5lFejZ"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor(np.genfromtxt(Path.cwd() / \"air_passengers.csv\"))  # Load Example\n",
        "\n",
        "# Default: 2D Torch tensor\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24, output_type=\"torch\")\n",
        "print(\"Predictions:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# 2D Numpy Array\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24, output_type=\"numpy\")\n",
        "print(\"Predictions:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# Iterate by patch\n",
        "# You can also use the forecast function as iterable. This might help with big datasets. All output_types are supported\n",
        "for i, fc_batch in enumerate(\n",
        "    model.forecast(context=[data, data, data, data, data], batch_size=2, output_type=\"torch\", yield_per_batch=True)\n",
        "):\n",
        "    quantiles, means = fc_batch\n",
        "    print(f\"Predictions batch {i}:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "try:\n",
        "    # QuantileForecast (GluonTS)\n",
        "    predictions_gluonts = model.forecast(context=data, prediction_length=24, output_type=\"gluonts\")\n",
        "    print(\"Predictions (GluonTS Quantile Forecast):\\n\", type(predictions_gluon), type(predictions_gluon[0]))\n",
        "    predictions_gluonts[0].plot()\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # To use the gluonts function you need to install the optional dependency\n",
        "    # pip install tirex[gluonts]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}